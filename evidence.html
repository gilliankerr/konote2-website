<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="The research foundation behind KoNote's design: feedback-informed practice, collaborative documentation, and participant-centred outcome tracking.">
  <title>Research Foundation — KoNote</title>
  <link rel="stylesheet" href="css/style.css">
  <link rel="icon" href="favicon.ico" sizes="32x32">
  <link rel="icon" href="favicon.svg" type="image/svg+xml">
  <link rel="icon" type="image/png" sizes="32x32" href="favicon-32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="favicon-16.png">
</head>
<body>
  <a href="#main" class="skip-nav">Skip to main content</a>

  <header class="site-header">
    <div class="container header-inner">
      <a href="index.html" class="site-logo"><img src="img/konote-logo.png" alt="KoNote" width="166" height="32"></a>
      <button class="nav-toggle" aria-expanded="false" aria-controls="main-nav">
        Menu
      </button>
      <nav class="site-nav" id="main-nav" aria-label="Main navigation">
        <a href="index.html">Home</a>
        <a href="features.html">Features</a>
        <a href="evidence.html" aria-current="page">Evidence</a>
        <a href="getting-started.html">Getting Started</a>
        <a href="documentation.html">Documentation</a>
        <a href="security.html">Security</a>
        <a href="services.html">Services</a>
        <a href="faq.html">FAQ</a>
      </nav>
    </div>
  </header>

  <main id="main">
    <section class="hero">
      <div class="container">
        <h1>Research Foundation</h1>
        <p class="hero-tagline">
          KoNote is designed around research on what helps participants succeed —
          not just what's convenient for agencies or funders.
        </p>
      </div>
    </section>

    <section>
      <div class="container">
        <h2>Why This Matters</h2>
        <p>
          Most outcome tracking software is designed backward. It starts with funder
          reporting requirements and works down to data collection. Participants become
          data sources rather than partners in their own progress.
        </p>
        <p>
          KoNote takes a different approach. We started with research on what actually
          improves participant outcomes, then designed software to support those practices.
          The reporting features exist, but they're not the foundation.
        </p>
      </div>
    </section>

    <section class="alt-bg">
      <div class="container">
        <h2>The Research</h2>

        <div class="card-grid">
          <div class="card">
            <h3>Feedback-Informed Treatment</h3>
            <p>
              Research by Scott Miller, Barry Duncan, and colleagues has consistently
              shown that routinely collecting client feedback and using it to guide
              services leads to significantly better outcomes. Clients are more likely
              to achieve meaningful change, and at-risk cases show the greatest improvement.
            </p>
            <p>
              The key finding: the act of systematically asking clients about their
              experience strengthens the working relationship — and that relationship
              is the strongest predictor of outcomes across service types.
            </p>
            <p class="text-muted">
              <strong>Key source:</strong> Miller, S.D., Duncan, B.L., Brown, J., Sorrell, R., &amp; Chalk, M.B. (2006).
              Using formal client feedback to improve retention and outcome: Making ongoing, real-time assessment feasible.
              <em>Journal of Brief Therapy</em>, 5(1), 5-22.
            </p>
          </div>

          <div class="card">
            <h3>Collaborative Documentation</h3>
            <p>
              Studies on collaborative documentation — where clients participate in
              creating their own records — show that most clients find it helpful
              and that it improves treatment adherence. When clients see and contribute
              to what's being written about them, trust increases.
            </p>
            <p>
              Transparency isn't just ethical; it's clinically effective. Clients
              sense alliance ruptures before service providers do. Routine feedback
              catches problems early, before clients disengage.
            </p>
            <p class="text-muted">
              <strong>Key source:</strong> Stanhope, V., Ingoglia, C., Schmelter, B., &amp; Marcus, S.C. (2013).
              Impact of person-centered planning and collaborative documentation on treatment adherence.
              <em>Psychiatric Services</em>, 64(1), 76-79.
            </p>
          </div>

          <div class="card">
            <h3>Brevity and Simplicity</h3>
            <p>
              Implementation research consistently shows that brief tools see better
              compliance than lengthy ones. Even single-item measures can be
              psychometrically valid when designed well. The Outcome Rating Scale
              and Session Rating Scale work because each takes under a minute.
            </p>
            <p>
              When feedback tools feel like administrative burden rather than clinical
              support, compliance becomes "empty" — going through the motions without
              genuine engagement.
            </p>
            <p class="text-muted">
              <strong>Key source:</strong> Campbell, A., &amp; Hemsley, S. (2009).
              Outcome Rating Scale and Session Rating Scale in psychological practice: Clinical utility of ultra-brief measures.
              <em>Clinical Psychologist</em>, 13(1), 1-9.
            </p>
          </div>
        </div>
      </div>
    </section>

    <section>
      <div class="container">
        <h2>How This Shaped KoNote</h2>
        <p>
          Each research finding informed specific design decisions:
        </p>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr>
                <th>Research Finding</th>
                <th>KoNote Design Response</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Asking for feedback strengthens the relationship</td>
                <td>Progress notes prompt for participant perspective, not just staff observations</td>
              </tr>
              <tr>
                <td>Clients know when something isn't working</td>
                <td>Progress charts are designed to be shared with participants, not hidden in reports</td>
              </tr>
              <tr>
                <td>Transparency builds trust</td>
                <td>The interface is designed so staff can show participants their own records</td>
              </tr>
              <tr>
                <td>Brevity improves compliance</td>
                <td>Quick notes are genuinely quick — structured notes only when needed</td>
              </tr>
              <tr>
                <td>Feedback should inform the relationship, not a report</td>
                <td>Metrics connect to individual plans, not just aggregate reporting</td>
              </tr>
              <tr>
                <td>Consent is foundational</td>
                <td>Participant setup requires consent confirmation before any data entry</td>
              </tr>
              <tr>
                <td>Implementation matters as much as tools</td>
                <td>Customisable terminology and workflows to fit how you actually work</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </section>

    <section class="alt-bg">
      <div class="container">
        <h2>Outcome Measurement</h2>
        <p>
          KoNote's metrics aren't arbitrary — they're built on over 50 years of research
          in goal-setting, self-efficacy, and outcome measurement. Three distinct dimensions
          — Goal Progress, Self-Efficacy, and Satisfaction — capture the full picture of
          participant change. Each is measured through participant self-report, which is
          the valid methodology for subjective outcomes. And KoNote's AI goal builder applies
          eight research-grounded criteria to help coaches write targets that actually
          drive better outcomes.
        </p>

        <div class="card-grid">
          <div class="card">
            <h3>Specific Goals Work Better</h3>
            <p>
              A goal like "build confidence with English" sounds reasonable, but research
              shows it leads to dramatically worse outcomes. Locke and Latham's meta-analyses
              across 35 years found that specific goals produce 250% better performance
              than vague "do your best" goals — not just better measurement, but better
              actual participant progress.
            </p>
            <p>
              This isn't about being pedantic. Specific goals work because they direct
              attention, energise effort, increase persistence, and trigger strategy
              development. KoNote's AI goal builder pushes coaches toward specificity —
              validating targets against criteria like observable behaviour, conditions,
              and success thresholds — because it genuinely helps participants succeed.
            </p>
            <p class="text-muted">
              <strong>Key sources:</strong> Locke, E.A. &amp; Latham, G.P. (2002). Building a practically
              useful theory of goal setting and task motivation.
              <em>American Psychologist, 57</em>(9), 705–717.
              Doran, G.T. (1981). There's a S.M.A.R.T. way to write management's goals and objectives.
              <em>Management Review, 70</em>(11), 35–36.
            </p>
          </div>

          <div class="card">
            <h3>Self-Report Is Valid</h3>
            <p>
              A common concern is that self-report metrics are "soft" or less reliable than
              objective measures. The evidence says otherwise. For subjective experiences —
              confidence, satisfaction, perceived progress — the participant's own report
              isn't a fallback. It is the primary valid measure. The NIH's PROMIS framework,
              the most comprehensive patient-reported outcome system ever built, is founded
              on exactly this principle.
            </p>
            <p>
              What makes self-report valid isn't who reports — it's how the question is
              anchored. Self-efficacy (a person's belief in their ability to perform
              specific tasks) must be measured domain-specifically. You can't just ask
              "are you confident?" You need to ask about specific behaviours: "How sure
              do you feel about being able to cook a healthy meal?" KoNote follows this
              principle — every metric is anchored to the specific target behaviour.
            </p>
            <p class="text-muted">
              <strong>Key sources:</strong> Bandura, A. (2006). Guide for constructing
              self-efficacy scales. In F. Pajares &amp; T. Urdan (Eds.),
              <em>Self-efficacy beliefs of adolescents</em>.
              <a href="https://commonfund.nih.gov/promis">PROMIS — NIH Common Fund</a>.
            </p>
          </div>

          <div class="card">
            <h3>Three Dimensions, Not One</h3>
            <p>
              Factor analyses across multiple validated frameworks consistently identify
              three distinct dimensions of outcome: what a person is <em>doing</em>
              (functional status), what they <em>believe they can do</em> (self-efficacy),
              and how they <em>feel about</em> their situation (satisfaction). These are
              moderately correlated but can diverge in clinically meaningful ways.
            </p>
            <p>
              Each divergence pattern tells the coach something different. High progress
              but low self-efficacy means "I'm doing it but I don't trust myself yet" —
              fragile change that needs encouragement. High progress but low satisfaction
              means the goal itself may be misaligned. Measuring all three catches patterns
              that a single metric would miss.
            </p>
            <p class="text-muted">
              <strong>Key sources:</strong> Perera, H.N. et al. (2018). Resolving
              dimensionality problems with WHOQOL-BREF.
              <em>Assessment, 25</em>(8), 1014–1025.
              Scholz, U. et al. (2002). Is general self-efficacy a universal construct?
              <em>European Journal of Psychological Assessment, 18</em>(3), 242–251.
            </p>
          </div>

          <div class="card">
            <h3>Individualised Measurement</h3>
            <p>
              Goal Attainment Scaling, developed by Kiresuk and Sherman in 1968, is the
              gold standard for individualised outcome measurement in social and health
              services. Each participant's goals are scaled on a continuum where the
              "expected" level is defined collaboratively — in concrete, observable terms —
              before the work begins.
            </p>
            <p>
              KoNote's AI-generated target-specific metrics draw on this approach. Each
              level describes an observable state defined at goal creation — not generic
              levels applied the same way to every participant. Coaches can accept, edit,
              or decline these AI-generated scales, keeping the human in the loop.
            </p>
            <p class="text-muted">
              <strong>Key source:</strong> Kiresuk, T.J. &amp; Sherman, R.E. (1968).
              Goal attainment scaling: A general method for evaluating comprehensive
              community mental health programs.
              <em>Community Mental Health Journal, 4</em>, 443–453.
            </p>
          </div>
        </div>
      </div>
    </section>

    <section>
      <div class="container">
        <h2>From Research to Metrics</h2>
        <p>
          Each research finding informed specific design decisions in KoNote's outcome measurement system:
        </p>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr>
                <th>Research Finding</th>
                <th>KoNote Design Response</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Specific goals produce 250% better outcomes (Locke &amp; Latham)</td>
                <td>AI goal builder validates targets against 8 research-grounded criteria</td>
              </tr>
              <tr>
                <td>Self-efficacy must be domain-specific (Bandura)</td>
                <td>Self-efficacy prompt asks about the specific target behaviour, not generic confidence</td>
              </tr>
              <tr>
                <td>Self-report is gold standard for subjective outcomes (PROMIS)</td>
                <td>All three metrics are participant self-report with behaviourally anchored levels</td>
              </tr>
              <tr>
                <td>Three distinct dimensions emerge in factor analyses</td>
                <td>Three universal metrics per target: Goal Progress, Self-Efficacy, Satisfaction</td>
              </tr>
              <tr>
                <td>"How sure do you feel" is less loaded than "how confident"</td>
                <td>Self-efficacy uses softer phrasing that works in trauma-informed practice</td>
              </tr>
              <tr>
                <td>Independence is a culturally specific value</td>
                <td>Goal Progress level 5 says "part of my life" not "independently"</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </section>

    <section class="alt-bg">
      <div class="container">
        <h2>What We're Not Claiming</h2>

        <div class="notice notice-info">
          <p class="notice-title">Important distinction</p>
          <p>
            The research cited above studied clinical practices — not this software.
            KoNote is designed to <em>support</em> feedback-informed practice, but
            we haven't conducted randomised trials of KoNote itself.
          </p>
        </div>

        <p>
          To be clear about what we're saying:
        </p>

        <ul>
          <li>
            <strong>We are saying:</strong> Research shows that feedback-informed
            practice and collaborative documentation improve client outcomes.
            KoNote is designed to make those practices easier to implement.
          </li>
          <li>
            <strong>We are not saying:</strong> Using KoNote will automatically
            improve your outcomes. That depends on how you use it, how you implement it,
            and whether it fits your context.
          </li>
        </ul>

        <p>
          KoNote is new software. We'd welcome partnerships with researchers interested
          in evaluating its effectiveness in real-world settings.
        </p>
      </div>
    </section>

    <section>
      <div class="container">
        <h2>Implementation Matters</h2>

        <p>
          The research is also clear about what goes wrong. Feedback tools fail when:
        </p>

        <ul>
          <li>Staff perceive them as surveillance rather than support</li>
          <li>The feedback goes into a database but doesn't inform the next session</li>
          <li>Filling in forms disrupts the human moment in a conversation</li>
          <li>Tools are too long or complex for routine use</li>
        </ul>

        <p>
          KoNote can't solve these problems by itself. Software is a tool, not a solution.
          Whether feedback-informed practice works at your agency depends on:
        </p>

        <ul>
          <li>Leadership commitment to using feedback, not just collecting it</li>
          <li>Staff training on how to invite honest feedback from participants</li>
          <li>A culture where participant input genuinely shapes service delivery</li>
          <li>Realistic expectations about what data can and can't tell you</li>
        </ul>

        <p>
          If you're looking for software that will magically improve your outcomes
          without changing anything else, KoNote isn't that. If you're looking for
          a tool that supports the practices research shows actually work, we've
          tried to build that.
        </p>
      </div>
    </section>

    <section class="alt-bg">
      <div class="container text-center">
        <h2>Questions?</h2>
        <p class="text-muted mb-8">
          Read more about KoNote's features, or get in touch if you'd like to discuss
          how it might fit your agency's approach.
        </p>
        <div class="btn-group" style="justify-content: center;">
          <a href="features.html" class="btn btn-primary">See Features</a>
          <a href="services.html" class="btn btn-secondary">Professional Services</a>
        </div>
      </div>
    </section>
  </main>

  <footer class="site-footer">
    <div class="container footer-content">
      <div class="footer-links">
        <a href="https://github.com/LogicalOutcomes/konote">GitHub Repository</a>
        <a href="documentation.html">Documentation</a>
        <a href="faq.html">FAQ</a>
        <a href="services.html">Professional Services</a>
      </div>
      <p class="footer-copyright">
        KoNote is open source software under the MIT License.
      </p>
    </div>
  </footer>

  <script>
    const navToggle = document.querySelector('.nav-toggle');
    const nav = document.querySelector('.site-nav');
    if (navToggle && nav) {
      navToggle.addEventListener('click', () => {
        const isOpen = nav.classList.toggle('is-open');
        navToggle.setAttribute('aria-expanded', isOpen);
      });
    }
  </script>
</body>
</html>
